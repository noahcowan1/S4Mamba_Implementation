{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8rq7yJWgAlMg",
    "outputId": "ab92f6ce-0c17-4cb9-d604-eb73a69b4516"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "save_dir = \"HW4_saved_items/\""
   ],
   "metadata": {
    "id": "oe5GuAlrA5M9",
    "ExecuteTime": {
     "end_time": "2024-03-14T02:08:51.009225Z",
     "start_time": "2024-03-14T02:08:51.007675Z"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Set Color Palette"
   ],
   "metadata": {
    "collapsed": false,
    "id": "hsjEQFNJ_Bdq"
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "hiroshige = dict(colors=(\"#e76254\", \"#ef8a47\", \"#f7aa58\", \"#ffd06f\",\n",
    "                           \"#ffe6b7\", \"#aadce0\", \"#72bcd5\", \"#528fad\",\n",
    "                           \"#376795\", \"#1e466e\"),\n",
    "                 order=(6, 2, 9, 3, 7, 5, 1, 10, 4, 8))\n",
    "\n",
    "monet = dict(colors=(\"#4e6d58\", \"#749e89\", \"#abccbe\", \"#e3cacf\",\n",
    "                   \"#c399a2\", \"#9f6e71\", \"#41507b\", \"#7d87b2\",\n",
    "                   \"#c2cae3\"),\n",
    "           order=(2, 5, 8, 3, 4, 9, 1, 6, 7))\n",
    "kandinsky = dict(colors=(\"#3b7c70\", \"#ce9642\", \"#898e9f\", \"#3b3a3e\"),\n",
    "                 order=(1, 2, 3, 4))\n",
    "\n",
    "tara=dict(colors=(\"#eab1c6\", \"#d35e17\", \"#e18a1f\", \"#e9b109\", \"#829d44\"),\n",
    "          order=(1, 3, 2, 5, 4))\n",
    "\n",
    "klimt=dict(colors=(\"#df9ed4\", \"#c93f55\", \"#eacc62\", \"#469d76\", \"#3c4b99\", \"#924099\"),\n",
    "           order=(5, 2, 3, 4, 6, 1))\n",
    "\n",
    "troy=dict(colors=(\"#421401\", \"#6c1d0e\", \"#8b3a2b\", \"#c27668\",\n",
    "                  \"#7ba0b4\", \"#44728c\", \"#235070\", \"#0a2d46\"),\n",
    "          order=(2, 7, 4, 5, 1, 8, 3, 6))\n",
    "\n",
    "def get_color(idx, colors_dict=hiroshige):\n",
    "    \"\"\"\n",
    "    Helper function to get a color from the defined color dictionary.\n",
    "    In order, starting at 0\n",
    "    \"\"\"\n",
    "    return colors_dict['colors'][colors_dict['order'].index(idx+1)]"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T05:19:31.276173Z",
     "start_time": "2024-03-07T05:19:31.270772Z"
    },
    "id": "1K3bU3GQ_Bdq"
   },
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZ-AwbZ4ySCJ"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Xd4fRbWr15Yp",
    "ExecuteTime": {
     "end_time": "2024-03-07T05:19:35.439274Z",
     "start_time": "2024-03-07T05:19:35.437505Z"
    }
   },
   "outputs": [],
   "source": [
    "# can take around 30s\n",
    "%%capture\n",
    "! pip install datasets #huggingface datasets library\n",
    "! pip install --upgrade pyarrow\n",
    "! pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "_5IXGh6OOBZV",
    "ExecuteTime": {
     "end_time": "2024-03-06T17:36:07.782895Z",
     "start_time": "2024-03-06T17:36:07.775952Z"
    }
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import csv\n",
    "\n",
    "# torch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from dataclasses import dataclass\n",
    "from einops import rearrange, repeat, einsum\n",
    "\n",
    "# hugging face imports\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        device_func = \"mps\"\n",
    "    elif torch.cuda.is_available():\n",
    "        device_func = \"cuda\"\n",
    "    else:\n",
    "        device_func = \"cpu\"\n",
    "    return device_func"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T05:19:35.905879Z",
     "start_time": "2024-03-07T05:19:35.903584Z"
    },
    "id": "g89scjkN_Bdr"
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.manual_seed(305)\n",
    "\n",
    "device = get_device()\n",
    "assert device=='mps' or device=='cuda', \"you need to change runtime type to GPU\""
   ],
   "metadata": {
    "id": "mAXAf1YO_Bdr"
   },
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "A_Z5Jh74DH_E",
    "ExecuteTime": {
     "end_time": "2024-03-06T17:45:38.846400Z",
     "start_time": "2024-03-06T17:45:38.843385Z"
    }
   },
   "outputs": [],
   "source": [
    "# hyperparams and helper functions\n",
    "SMALL_ITERS = 1000\n",
    "LARGE_ITERS = 2000\n",
    "context_window_size = 256\n",
    "chunk_size = 512 # BERT can only take max input size 512 characters\n",
    "\n",
    "def chunk_string(string, size):\n",
    "    \"\"\"\n",
    "    Splits a string into chunks of a specified size.\n",
    "\n",
    "    :param string: The string to be chunked.\n",
    "    :param size: The desired chunk size.\n",
    "    :return: A list of string chunks.\n",
    "    \"\"\"\n",
    "    return [string[i:i+size] for i in range(0, len(string), size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lF6dgHnhOprg"
   },
   "source": [
    "## Part 0: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WF0_bhXNOxeS"
   },
   "source": [
    "### 0.1: Loading the dataset\n",
    "\n",
    "The first step is to actually download the dataset. We will be using a dataset on [huggingface](https://huggingface.co/). You can think of hugging face as the sklearn of deep learning.\n",
    "\n",
    "The dominant mode for preprocessing textual data is to tokenize it, that is, to split the dataset into a finite vocabulary of tokens. Then, we can set up a dictionary where counting numbers map to tokens. Tokens can be characters, or words, or subwords; in fact, the \"best\" way to tokenize text is an active area of research. For our baseline, we will use a tokenizer that microsoft created for code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "53dGz7ExDkUv",
    "ExecuteTime": {
     "end_time": "2024-03-05T00:26:10.822788Z",
     "start_time": "2024-03-05T00:26:08.093102Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/CodeBERT-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "BAdrvcIbORig",
    "ExecuteTime": {
     "end_time": "2024-03-05T00:26:23.882801Z",
     "start_time": "2024-03-05T00:26:22.198576Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the concatenated data\n",
    "raw_data = pd.read_csv(\"https://raw.githubusercontent.com/slinderman/stats305b/winter2024/assignments/hw4/python_corpus_4M.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LFZ2or4BO2w3",
    "ExecuteTime": {
     "end_time": "2024-03-05T00:26:57.613981Z",
     "start_time": "2024-03-05T00:26:27.981074Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6407047c-8c34-483d-c45a-59e38af74f13"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (523 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4000596 tokens have been loaded in\n"
     ]
    }
   ],
   "source": [
    "# should take around 3 min to load in around 4M tokens\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "tokens = torch.tensor([], dtype=torch.long)\n",
    "for index, row in raw_data.iterrows():\n",
    "    text = row[0]\n",
    "    chunks = chunk_string(text, chunk_size)\n",
    "    n = len(chunks)\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        new_tokens = torch.tensor(tokenizer.encode(chunk, add_special_tokens=True))\n",
    "\n",
    "        # logic to avoid incorrectly adding in start and end sequence tokens as an artifact of chunking\n",
    "        if idx == 0:\n",
    "            tokens = torch.cat((tokens, new_tokens[:-1]), dim=0)\n",
    "        elif idx == n-1:\n",
    "            tokens = torch.cat((tokens, new_tokens[1:]), dim=0)\n",
    "        else:\n",
    "            tokens = torch.cat((tokens, new_tokens[1:-1]), dim=0)\n",
    "\n",
    "print(f\"{len(tokens)} tokens have been loaded in\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUnScCoUCRI0"
   },
   "source": [
    "### Question 0.2: Examining the tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rz0XmuXCdGJ"
   },
   "source": [
    "Let's use the same prompts we used in Part 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "KPbmLgmmChVg",
    "ExecuteTime": {
     "end_time": "2024-03-05T00:26:57.617613Z",
     "start_time": "2024-03-05T00:26:57.615347Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt_1_text = \\\n",
    "\"\"\"def newton(eta, N, X, y, gamma, beta=None):\n",
    "  \\\"\"\"\n",
    "  Performs Newton's method on the negative average log likelihood with an\n",
    "  l2 regularization term\n",
    "\n",
    "  beta: torch.Tensor, of shape (teams)\n",
    "  X: torch.Tensor, the covariate matrix, of shape (-1, teams)\n",
    "  y: torch.Tensor, the response vector, of shape (teams)\n",
    "  gamma: float, the scale parameter for the regularization\n",
    "  beta: torch.Tensor, the starting point for gradient descent, if specified\n",
    "  \\\"\"\"\n",
    "\n",
    "  if beta is None:\n",
    "    # Instantiate the beta vector at a random point\n",
    "    beta = torch.randn(X.shape[1])\n",
    "  else:\n",
    "    beta = torch.clone(beta)\n",
    "\n",
    "  loss = []\n",
    "\n",
    "  # Instantiate a list to store the loss throughout the gradient descent\n",
    "  # path\n",
    "  for i in tqdm(range(N)):\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "gZpeZjvqCnmH",
    "ExecuteTime": {
     "end_time": "2024-03-05T00:27:00.206799Z",
     "start_time": "2024-03-05T00:27:00.204367Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt_2_text = \\\n",
    "\"\"\"import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def normalize(x, axis=-1):\n",
    "    \\\"\"\"Performs L2-Norm.\\\"\"\"\n",
    "    num = x\n",
    "    denom = torch.norm(x, 2, axis, keepdim=True).expand_as(x) + 1e-12\n",
    "    return num / denom\n",
    "\n",
    "def euclidean_dist(x, y):\n",
    "    \\\"\"\"Computes Euclidean distance.\\\"\"\"\n",
    "    m, n = x.size(0), y.size(0)\n",
    "    xx = torch.pow(x, 2).sum(1, keepdim=True).expand(m, n)\n",
    "    yy = torch.pow(x, 2).sum(1, keepdim=True).expand(m, m).t()\n",
    "    dist = xx + yy - 2 * torch.matmul(x, y.t())\n",
    "\n",
    "    dist = dist.clamp(min=1e-12).sqrt()\n",
    "\n",
    "    return dist\n",
    "\n",
    "\n",
    "def cosine_dist(x, y):\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFZUT77rCp3q"
   },
   "source": [
    "Here is what the tokenized output for the prompts looks like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hwg1_7kDxwY"
   },
   "source": [
    "### 0.3: Building our dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uk4UJm5SEMlB"
   },
   "source": [
    "There are around 50,000 tokens in the codebert vocab, but we only use around 20,000 of them. To make our lives easier, we just reindex the token indices to go from 1 to around 20,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "RZC0TYeaD6yj",
    "ExecuteTime": {
     "end_time": "2024-03-05T03:18:04.335868Z",
     "start_time": "2024-03-05T03:18:04.197175Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1c0c334f-bd07-4de2-c4e9-11b34df09549"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "there are 21970 distinct tokens in the vocabulary\n"
     ]
    }
   ],
   "source": [
    "# Get unique elements\n",
    "extra_tokens = torch.cat((torch.tensor(tokenizer.encode(prompt_1_text, add_special_tokens=True)),\n",
    "                          torch.tensor(tokenizer.encode(prompt_2_text, add_special_tokens=True))),\n",
    "                         dim=0)\n",
    "\n",
    "unique_tokens = torch.unique(torch.cat((tokens, extra_tokens), dim=0))\n",
    "\n",
    "# Create a mapping from code bert to ids that increment by one\n",
    "from_code_bert_dict = {element.item(): id for id, element in enumerate(unique_tokens)}\n",
    "\n",
    "# Create a reverse mapping from ids to code bert token ids\n",
    "to_code_bert_dict = {id: element for element, id in from_code_bert_dict.items()}\n",
    "\n",
    "vocab_size = len(unique_tokens)\n",
    "print(f\"there are {vocab_size} distinct tokens in the vocabulary\")\n",
    "\n",
    "# helper functions to move between code bert and simple ids\n",
    "def from_code_bert(tkn_lst):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    tkn_lst: a list of code bert tokens\n",
    "    Returns:\n",
    "    a list of simple ids\n",
    "    \"\"\"\n",
    "    tkns = [int(from_code_bert_dict[token]) for token in tkn_lst]\n",
    "    return tkns\n",
    "\n",
    "\n",
    "def to_code_bert(tkn_lst):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    tkn_lst: a list of simple ids\n",
    "    Returns:\n",
    "    a list of code bert tokens\n",
    "    \"\"\"\n",
    "    tkns = [int(to_code_bert_dict[token]) for token in tkn_lst]\n",
    "    return tkns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "pNOmdccJEXWk",
    "ExecuteTime": {
     "end_time": "2024-03-05T03:18:24.449548Z",
     "start_time": "2024-03-05T03:18:19.772556Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7bf7f1d9-03b4-40e8-e7fd-0e5b9d27cfee"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "there are 3600536 tokens in the training set\n",
      "there are 400060 tokens in the validation set\n",
      "there are 21970 distinct tokens in the vocabulary\n"
     ]
    }
   ],
   "source": [
    "# let's translate our dataset into our ids\n",
    "tokens_simple_id = torch.tensor([from_code_bert_dict[token.item()] for token in tokens])\n",
    "\n",
    "# split up the data into train and validation sets\n",
    "n = int(0.9 * len(tokens_simple_id)) # first 90% will be train, rest val\n",
    "train_data = tokens_simple_id.clone()[:n]\n",
    "val_data = tokens_simple_id.clone()[n:]\n",
    "\n",
    "print(f\"there are {len(train_data)} tokens in the training set\")\n",
    "print(f\"there are {len(val_data)} tokens in the validation set\")\n",
    "print(f\"there are {vocab_size} distinct tokens in the vocabulary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsOs0_diEcjY"
   },
   "source": [
    "We also write helper functions to get batches of data and to evaluate the loss of various models on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "AkAD0PfiEfjG",
    "ExecuteTime": {
     "end_time": "2024-03-05T03:18:45.159569Z",
     "start_time": "2024-03-05T03:18:45.155702Z"
    }
   },
   "outputs": [],
   "source": [
    "# function for getting batches of data\n",
    "def get_batch(split, context_window_size, device, batch_size=32):\n",
    "    \"\"\"\n",
    "    generate a small batch of data of inputs x and targets y\n",
    "\n",
    "    Args:\n",
    "        split: 'train' or 'val'\n",
    "        device: 'cpu' or 'cuda' (should be 'cuda' if available)\n",
    "    \"\"\"\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - context_window_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+context_window_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+context_window_size+1] for i in ix])\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    return x, y\n",
    "\n",
    "# helper function for tracking loss during training\n",
    "# given to you\n",
    "@torch.no_grad()\n",
    "def estimate_loss(model, eval_iters, context_window_size, device):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      model: model being evaluated\n",
    "      eval_iters: number of batches to average over\n",
    "      context_window_size: size of the context window\n",
    "      device: 'cpu' or 'cuda' (should be 'cuda' if available)\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split, context_window_size, device)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "start_context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(f\"shape is {start_context.shape}\")\n",
    "context1 = torch.tensor(from_code_bert(tokenizer.encode(prompt_1_text)[:-1]),\n",
    "                        device=device).reshape(1, -1) # (1, T)\n",
    "print(f\"shape is {context1.shape}\")\n",
    "context2 = torch.tensor(from_code_bert(tokenizer.encode(prompt_2_text)[:-1]),\n",
    "                        device=device).reshape(1, -1)\n",
    "print(f\"shape is {context2.shape}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "duRD0prGudOU",
    "outputId": "88be0d02-635b-4780-a204-b89443533de3"
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "shape is torch.Size([1, 1])\n",
      "shape is torch.Size([1, 225])\n",
      "shape is torch.Size([1, 263])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Adding temperature sampling to scale how creative logits are\n",
    "def temperature_sampling(logits, temperature=1.0):\n",
    "            \"\"\"\n",
    "            Args:\n",
    "              logits: (B, _, V), logits  gives the length V vector of logits for the next token prediction in string b up to t tokens\n",
    "              temperature: float, temperature scaling factor, closer to 0 means more conservative sampling, closer to infinity means more uniform sampling\n",
    "\n",
    "            returns:\n",
    "                (B, ) tensor of next token ids for each string in the batch\n",
    "            \"\"\"\n",
    "            B = logits.shape[0]\n",
    "            logits_updated = logits / temperature\n",
    "            probabilities = F.softmax(logits_updated, dim=-1)\n",
    "            next_token = torch.multinomial(probabilities.view(B, -1), num_samples=1)\n",
    "            return next_token"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T06:08:43.717308Z",
     "start_time": "2024-03-07T06:08:43.713445Z"
    },
    "id": "cBjhPGGF_Bdv"
   },
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "E2r390zbyz3O",
    "ExecuteTime": {
     "end_time": "2024-03-07T06:56:51.142412Z",
     "start_time": "2024-03-07T06:56:49.279326Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_or_load_model(save_dir,\n",
    "                        model_instantiation,\n",
    "                        model_file_name,\n",
    "                        learning_rate = 1e-2,\n",
    "                        iters = SMALL_ITERS,\n",
    "                        eval_iters = 200,\n",
    "                        context_window_size = context_window_size,\n",
    "                        device = device):\n",
    "  \"\"\"\n",
    "  Function to load a model saved in \"save_dir\" or train a new model if no file\n",
    "  exists in \"save_dir.\" The file should have name \"model_file_name_model\"\n",
    "\n",
    "  Args:\n",
    "    save_dir (str): directory to save model\n",
    "    model_instantiation (class): class of model to instantiate\n",
    "    model_file_name (str): name of file to save model to\n",
    "    learning_rate (float): learning rate for optimizer, if no file found\n",
    "  Returns:\n",
    "    Lists of losses for each iteration and evaluation iterations,\n",
    "    changes model as well\n",
    "  \"\"\"\n",
    "  try:\n",
    "      model_instantiation.load_state_dict(\n",
    "          torch.load(save_dir + f\"{model_file_name}_model.pt\"))\n",
    "      with open(save_dir + f\"loss_list_{model_file_name}.csv\", \"r\") as f:\n",
    "          reader = csv.reader(f)\n",
    "          next(reader, None)  # Skip the header\n",
    "          loss_list_model = [float(row[0]) for row in reader]\n",
    "      with open(save_dir + f\"loss_eval_{model_file_name}.csv\", \"r\") as f:\n",
    "          reader = csv.reader(f)\n",
    "          next(reader, None)  # Skip the header\n",
    "          loss_eval_list = [float(row[1]), float(row[2])]\n",
    "      return loss_list_model, loss_eval_list\n",
    "      print(\"Read in model from file\")\n",
    "  except:\n",
    "      print(\"No File Found, Training Model\")\n",
    "      # create a PyTorch optimizer\n",
    "      optimizer = torch.optim.AdamW(model_instantiation.parameters(),\n",
    "                                    lr=learning_rate)\n",
    "\n",
    "      eval_interval = eval_iters\n",
    "\n",
    "      loss_list_model = [] # list to store all losses\n",
    "      loss_eval_list = []  # list to store evaluation losses\n",
    "\n",
    "      for it in tqdm(range(iters)):\n",
    "          # every once in a while evaluate the loss on train and val sets\n",
    "          if it % eval_interval == 0 or it == iters - 1:\n",
    "              print(f\"iteration {it}\")\n",
    "              losses = estimate_loss(model_instantiation, eval_iters, context_window_size, device)\n",
    "              print(f\"step {it}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "              loss_eval_list.append([it, losses['train'], losses['val']])\n",
    "\n",
    "          # sample a batch of data\n",
    "          xb, yb = get_batch('train', context_window_size, device)\n",
    "\n",
    "          # evaluate the loss\n",
    "          logits, loss = model_instantiation(xb, yb)\n",
    "          loss_list_model.append(loss.detach().item())\n",
    "          optimizer.zero_grad(set_to_none=True)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "      torch.save(model_instantiation.state_dict(), save_dir + f\"{model_file_name}_model.pt\")\n",
    "\n",
    "      # Save batch losses to CSV\n",
    "      with open(save_dir + f\"loss_list_{model_file_name}.csv\",\n",
    "                \"w\", newline='') as f:\n",
    "          writer = csv.writer(f)\n",
    "          writer.writerow([\"Loss\"])\n",
    "          writer.writerows([loss_list_model])\n",
    "\n",
    "      # Save evaluation losses to CSV\n",
    "      with open(save_dir + f\"loss_eval_{model_file_name}.csv\", \"w\", newline='') as f:\n",
    "          writer = csv.writer(f)\n",
    "          writer.writerow([\"Iteration\", \"Train Loss\", \"Validation Loss\"])\n",
    "          writer.writerows(loss_eval_list)\n",
    "      return loss_list_model, loss_eval_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqCCiCYcKMD0"
   },
   "source": [
    "# Part 1. Baseline transformer model\n",
    "\n",
    "We now stack 6 `TransformerBlocks` (with a final layer norm applied after the blocks but before the logits) to create our basline `TransformerLM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "O_eBPiT-Yy0q",
    "ExecuteTime": {
     "end_time": "2024-03-07T07:24:13.851869Z",
     "start_time": "2024-03-07T07:24:13.848239Z"
    }
   },
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size, context_window_size, embed_size=384):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          head_size: int, size of the head embedding dimension (K)\n",
    "          context_window_size: int, number of tokens considered in the past for attention (T)\n",
    "          embed_size: int, size of the token embedding dimension (D)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.head_size = head_size\n",
    "        self.key = nn.Linear(embed_size, head_size, bias=False)\n",
    "        self.query = nn.Linear(embed_size, head_size, bias=False)\n",
    "        self.value = nn.Linear(embed_size, embed_size, bias=False)\n",
    "\n",
    "        # not a param of the model, so registered as a buffer\n",
    "        self.register_buffer('tril', torch.tril(\n",
    "            torch.ones(context_window_size, context_window_size)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x: (B,T,D) tensor of token embeddings\n",
    "\n",
    "        Returns:\n",
    "          (B,T,D) tensor of attention-weighted token embeddings\n",
    "        \"\"\"\n",
    "        _, T, _ = x.shape\n",
    "        attn_weights = self.query(x) @ self.key(x).transpose(-1, -2) #(-1,-2) # (B,T,T)\n",
    "        attn_weights = attn_weights.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        attn_weights = F.softmax(attn_weights / sqrt(self.head_size), dim=-1)\n",
    "        return attn_weights @ self.value(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "6vb8NU_s6Vfg",
    "ExecuteTime": {
     "end_time": "2024-03-07T08:11:10.625567Z",
     "start_time": "2024-03-07T08:11:10.622097Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, context_window_size, num_heads, head_size, embed_size=384):\n",
    "        super().__init__()\n",
    "        # my code below\n",
    "        self.heads = nn.ModuleList([Head(head_size, context_window_size, embed_size) for _ in range(num_heads)])\n",
    "        self.linear = nn.Linear(num_heads * embed_size, embed_size, bias=False) # Just doing a linear mapping to get back to vocab size\n",
    "\n",
    "    def forward(self, x):\n",
    "        head_outputs = [head(x) for head in self.heads] # List of num_heads # of (B,T,D) tensors\n",
    "        concat = torch.cat(head_outputs, dim=-1) # (B,T,D*H)\n",
    "        return self.linear(concat) # (B,T,V) learns a combination (might be slow, if so will just sum again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "1GbGqwKWJzOK",
    "ExecuteTime": {
     "end_time": "2024-03-07T03:41:11.807971Z",
     "start_time": "2024-03-07T03:41:11.805366Z"
    }
   },
   "outputs": [],
   "source": [
    "# run this cell to initialize this deep learning module that you should use in the code your write later\n",
    "# you don't need to edit this layer\n",
    "class FeedForward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity\n",
    "        Given to you, you don't need to write any code here!\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_size):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(embed_size, 4 * embed_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * embed_size, embed_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "hUDbIv9eISkf",
    "ExecuteTime": {
     "end_time": "2024-03-07T03:41:13.006642Z",
     "start_time": "2024-03-07T03:41:13.003723Z"
    }
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    \"\"\" Transformer block: communication across sequence length, followed by communication across embedding space\n",
    "        Uses multi-headed attention\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_size, block_size, embed_size=384, num_heads=6):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(embed_size)\n",
    "        self.ln2 = nn.LayerNorm(embed_size)\n",
    "\n",
    "        # TODO: your code below\n",
    "        self.feed_forward = FeedForward(embed_size)\n",
    "        head_size = embed_size // num_heads\n",
    "        self.mh_attention = MultiHeadAttention(vocab_size, block_size,\n",
    "                                                 num_heads, head_size,\n",
    "                                                 embed_size=384)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.mh_attention(self.ln1(x)) # communication over sequence length\n",
    "        x = x + self.feed_forward(self.ln2(x)) # communication across embedding space\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "t2veTg9N3ufJ",
    "ExecuteTime": {
     "end_time": "2024-03-07T03:41:14.102184Z",
     "start_time": "2024-03-07T03:41:14.096202Z"
    }
   },
   "outputs": [],
   "source": [
    "class TransformerLM(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, context_window_size, embed_size=384, num_heads=6, n_layers=6):\n",
    "        \"\"\"\n",
    "          Args:\n",
    "              vocab_size: int, number of tokens in the vocabulary (V)\n",
    "              context_window_size: int, size of the context window (T)\n",
    "              embed_size: int, embedding size (D)\n",
    "              num_heads: int, number of heads (H)\n",
    "              n_layers: int, number of layers (M)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, embed_size)\n",
    "        self.position_embedding_table = nn.Embedding(context_window_size, embed_size)\n",
    "        self.blocks = nn.Sequential(*[\n",
    "            TransformerBlock(vocab_size,\n",
    "                             context_window_size,\n",
    "                             embed_size=embed_size,\n",
    "                             num_heads=num_heads)\n",
    "            for _ in range(n_layers)])\n",
    "        self.context_window_size = context_window_size\n",
    "\n",
    "        # final layer norm\n",
    "        self.ln_f = nn.LayerNorm(embed_size)\n",
    "        self.lm_head = nn.Linear(embed_size, vocab_size)\n",
    "\n",
    "        # good initialization\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, token_ids, targets=None):\n",
    "        \"\"\"\n",
    "        Agrgs:\n",
    "            token_ids: tensor of integers, provides the contet, shape (B, T)\n",
    "            targets: tensor of integers, provides the tokens we are preidcitng, shape (B, T)\n",
    "        \"\"\"\n",
    "        B, T = token_ids.shape\n",
    "\n",
    "        # token_ids and targets are both (B, T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(token_ids) # (B, T, D)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T, D)\n",
    "        x = tok_emb + pos_emb # (B, T, D)\n",
    "\n",
    "\n",
    "        # Start of my code\n",
    "        logits = self.lm_head(self.ln_f(self.blocks(x))) # (B, T, V) # able to put all in one step because of sequential\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            logits_for_loss = logits.view(B*T, -1) # could do -1 here, but doing explicitly for clarity\n",
    "            targets_for_loss = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits_for_loss, targets_for_loss) # default reduction is mean, so we don't need to average\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, token_ids, max_new_tokens, temperature=1.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            token_ids: tensor of integers forming the context, shape (B, T)\n",
    "            max_new_tokens: int, max number of tokens to generate\n",
    "        \"\"\"\n",
    "        # done\n",
    "        generated_tokens = token_ids\n",
    "        for _ in range(max_new_tokens):\n",
    "            in_window = generated_tokens[:, -self.context_window_size:] # (B, T)\n",
    "            # Get the logits for the current sequence\n",
    "            logits, _ = self.forward(in_window)  # (B, T_current, V)\n",
    "            # Select the last token logits\n",
    "            next_token_logits = logits[:, -1, :]  # (B, V)\n",
    "            next_token = temperature_sampling(next_token_logits, temperature)  # Sample a new token\n",
    "            generated_tokens = torch.cat([generated_tokens, next_token], dim=1)  # (B, T_current + 1)\n",
    "        return generated_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JP8430nWKbZ6"
   },
   "source": [
    "Train your `TransformerLM` for `LARGE_ITERS` iterations and plot the loss curve. You may want to change the learning rate.\n",
    "\n",
    "We used a learning rate of `1e-4` and got to a final train loss of around 2.4 in around 30 mins of training."
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trans = TransformerLM(vocab_size, context_window_size)\n",
    "tlm = trans.to(device)"
   ],
   "metadata": {
    "id": "bRdrsGA7_Bd1"
   },
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "jsnbDpdhLeKo",
    "ExecuteTime": {
     "end_time": "2024-03-07T03:41:18.280389Z",
     "start_time": "2024-03-07T03:41:15.190412Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "cfa74e32-b2f4-4890-9b2d-594d3865159e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No File Found, Training Model\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r  0%|          | 0/4000 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iteration 0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r  0%|          | 1/4000 [00:43<48:27:13, 43.62s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "step 0: train loss 10.0605, val loss 10.0547\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 10%|█         | 400/4000 [01:49<09:58,  6.02it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iteration 400\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r 10%|█         | 401/4000 [02:33<13:20:37, 13.35s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "step 400: train loss 3.7862, val loss 3.9551\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 20%|██        | 800/4000 [03:39<08:49,  6.04it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iteration 800\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r 20%|██        | 801/4000 [04:23<11:52:43, 13.37s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "step 800: train loss 3.2139, val loss 3.5743\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 30%|███       | 1200/4000 [05:29<07:48,  5.98it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iteration 1200\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r 30%|███       | 1201/4000 [06:13<10:23:47, 13.37s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "step 1200: train loss 2.8353, val loss 3.3502\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 40%|████      | 1600/4000 [07:20<06:40,  5.99it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iteration 1600\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r 40%|████      | 1601/4000 [08:04<8:55:05, 13.38s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "step 1600: train loss 2.5653, val loss 3.1992\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 50%|█████     | 2000/4000 [09:10<05:32,  6.02it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iteration 2000\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r 50%|█████     | 2001/4000 [09:54<7:25:17, 13.37s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "step 2000: train loss 2.3548, val loss 3.1136\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 60%|██████    | 2400/4000 [11:00<04:26,  6.01it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iteration 2400\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r 60%|██████    | 2401/4000 [11:44<5:55:46, 13.35s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "step 2400: train loss 2.1837, val loss 3.0289\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 70%|███████   | 2800/4000 [12:50<03:20,  5.99it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iteration 2800\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r 70%|███████   | 2801/4000 [13:35<4:27:20, 13.38s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "step 2800: train loss 2.0350, val loss 2.9783\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 80%|████████  | 3200/4000 [14:41<02:13,  6.01it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iteration 3200\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r 80%|████████  | 3201/4000 [15:25<2:58:06, 13.38s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "step 3200: train loss 1.8885, val loss 2.9517\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 90%|█████████ | 3600/4000 [16:31<01:06,  6.04it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iteration 3600\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\r 90%|█████████ | 3601/4000 [17:15<1:28:59, 13.38s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "step 3600: train loss 1.7749, val loss 2.9469\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|█████████▉| 3999/4000 [18:21<00:00,  5.98it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iteration 3999\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 4000/4000 [19:05<00:00,  3.49it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "step 3999: train loss 1.6909, val loss 2.9300\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_list_tlm, loss_eval_tlm = train_or_load_model(save_dir,\n",
    "                                                     tlm,\n",
    "                                                     \"tlm_final\",\n",
    "                                                     learning_rate = 1e-4,\n",
    "                                                     iters = 4000,\n",
    "                                                     eval_iters = 400,\n",
    "                                                     context_window_size = context_window_size,\n",
    "                                                     device = device)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(loss_list_tlm)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "806MtFmgHJsu",
    "outputId": "d954421c-c602-414e-a59c-ec35630a0eac"
   },
   "execution_count": 52,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Jgvwzv5Ko7c"
   },
   "source": [
    "Generate an unconditional sample of length `context_window_size` from your trained `TransformerLM`, and also prompt it with the two prompts we gave you. How does the output look? Discuss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "89-1t6MRLVi4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1b5ff258-6ef5-41e3-cf66-4fbc3e76059b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "shape is torch.Size([1, 1])\n",
      "shape is torch.Size([1, 225])\n",
      "shape is torch.Size([1, 263])\n"
     ]
    }
   ],
   "source": [
    "# the contexts for the different prompts\n",
    "start_context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "print(f\"shape is {start_context.shape}\")\n",
    "context1 = torch.tensor(from_code_bert(tokenizer.encode(prompt_1_text)[:-1]), device=device).reshape(1, -1) # (1, T)\n",
    "print(f\"shape is {context1.shape}\")\n",
    "context2 = torch.tensor(from_code_bert(tokenizer.encode(prompt_2_text)[:-1])).to(device).reshape(1, -1)\n",
    "print(f\"shape is {context2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "9_rxT1iSKzdO",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2b29c774-3b92-4543-ed90-f860f5ddc15c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<s>#!/usr/license-negative/sr\n",
      "import requests.bin\n",
      "import json-'\n",
      "\n",
      "\n",
      "def stFileize():\n",
      "     url = f'{http://localhostmap(uuid.irport)}\\array\\n'\n",
      "\n",
      "    animal = os.se 9000\n",
      "    data = data.read(r, myer, login)\n",
      "\n",
      "    returnnd\n",
      "\n",
      "with open('h', '/where.json') as f:\n",
      "    def rv(len, loop):\n",
      "        yieldel\n",
      "\n",
      "    dt = [f for x in size:\n",
      "            f.rotation()\n",
      "    raise TypeError()\n",
      "\n",
      "    print('all required uri' ')\n",
      "\n",
      "    for x, v) in file.items():\n",
      "        res = list()\n",
      "        None\n",
      "        result = svti()\n",
      "        print(top + b)\n",
      "    else:\n",
      "        # Config from config action():\n"
     ]
    }
   ],
   "source": [
    "# unconditional generate from the transformer model\n",
    "uncond_gen = (tlm.generate(start_context, max_new_tokens=context_window_size)[0].tolist())\n",
    "print(tokenizer.decode(to_code_bert(uncond_gen)))"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# generate from the prompts\n",
    "gen_1 = tlm.generate(context1, max_new_tokens=context_window_size, temperature=.8)\n",
    "gen_2 = tlm.generate(context2, max_new_tokens=context_window_size, temperature=.8)\n",
    "# decode the generated tokens\n",
    "gen_1_text = tokenizer.decode(to_code_bert(gen_1[0].cpu().numpy()))\n",
    "gen_2_text = tokenizer.decode(to_code_bert(gen_2[0].cpu().numpy()))"
   ],
   "metadata": {
    "id": "8pvqksayF1Uf"
   },
   "execution_count": 61,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "1-FeFwD8K4jj",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "16d1d625-545b-48d1-f2f3-c75aa7b3686e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "generated text from prompt 1: <s>def newton(eta, N, X, y, gamma, beta=None):\n",
      "  \"\"\"\n",
      "  Performs Newton's method on the negative average log likelihood with an\n",
      "  l2 regularization term\n",
      "\n",
      "  beta: torch.Tensor, of shape (teams)\n",
      "  X: torch.Tensor, the covariate matrix, of shape (-1, teams)\n",
      "  y: torch.Tensor, the response vector, of shape (teams)\n",
      "  gamma: float, the scale parameter for the regularization\n",
      "  beta: torch.Tensor, the starting point for gradient descent, if specified\n",
      "  \"\"\"\n",
      "\n",
      "  if beta is None:\n",
      "    # Instantiate the beta vector at a random point\n",
      "    beta = torch.randn(X.shape[1])\n",
      "  else:\n",
      "    beta = torch.clone(beta)\n",
      "\n",
      "  loss = []\n",
      "\n",
      "  # Instantiate a list to store the loss throughout the gradient descent\n",
      "  # path\n",
      "  for i in tqdm(range(N)):\n",
      "    l1 = lexporter.get_for_info()\n",
      "    with pytest.raises(\n",
      "        \"AtesVal`Eets if run):\n",
      "        return\n",
      "\n",
      "    if n:\n",
      "        # handle the def for 0\n",
      "        raise ValueError(\n",
      "            self.eb1, self.cuda_check, r1.get_consumer(\"a\"), params)\n",
      "    # get the query token unit edge\n",
      "        # Get the JSON support print(self.default)\n",
      "        sys.stderr.append(\"Local address: {}\".format(self.get('nan')))\n",
      "        return len(self.get('exmar.getid')):\n",
      "        \n",
      "    @patch('cursor', '')\n",
      "    def _has_grant_mean(self, not self):\n",
      "        return {}\n"
     ]
    }
   ],
   "source": [
    "print(f\"generated text from prompt 1: {gen_1_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "tA2TnXBzK6mN",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "acede177-030a-47f1-b7d4-18e4cc035729"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "generated text from prompt 2: <s>import torch\n",
      "import torch.nn.functional as F\n",
      "\n",
      "\n",
      "def normalize(x, axis=-1):\n",
      "    \"\"\"Performs L2-Norm.\"\"\"\n",
      "    num = x\n",
      "    denom = torch.norm(x, 2, axis, keepdim=True).expand_as(x) + 1e-12\n",
      "    return num / denom\n",
      "\n",
      "def euclidean_dist(x, y):\n",
      "    \"\"\"Computes Euclidean distance.\"\"\"\n",
      "    m, n = x.size(0), y.size(0)\n",
      "    xx = torch.pow(x, 2).sum(1, keepdim=True).expand(m, n)\n",
      "    yy = torch.pow(x, 2).sum(1, keepdim=True).expand(m, m).t()\n",
      "    dist = xx + yy - 2 * torch.matmul(x, y.t())\n",
      "\n",
      "    dist = dist.clamp(min=1e-12).sqrt()\n",
      "\n",
      "    return dist\n",
      "\n",
      "\n",
      "def cosine_dist(x, y):\n",
      "    \"\"\"\n",
      "    Returns a yps results = []\n",
      "\n",
      "    assert R.MC_RTS\n",
      "\n",
      "    # Check that the function we check all\n",
      "    # classification elements that is case\n",
      "    if we.\n",
      "\n",
      "     orange_sqrtd(z) in pear331/256, zeta1, and reduce\n",
      "    # cycle are want\n",
      "    def test_start_view(self):\n",
      "        x, y = draw_transargs(self.num_grad, x, other_features, angle=np.sy))\n",
      "        x =conv * np.random.randint(0, 3, 5))\n",
      "        x = x * x\n",
      "        x = self.concat([x, x])\n",
      "        x, y = x + x, y * y = x\n",
      "\n",
      "        x = x for x in x in [(x, y, y):\n",
      "            y = x = x,\n"
     ]
    }
   ],
   "source": [
    "# conditional generation of cosine distance\n",
    "print(f\"generated text from prompt 2: {gen_2_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Izr1wTOjzlo"
   },
   "source": [
    "## Part 2: Mini-Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5lF3jFrQj1f4"
   },
   "source": [
    "Quick recap: So far we have\n",
    "\n",
    "1. Preprocessed the python code dataset by encoding text into integer tokens.\n",
    "2. Implemented single headed attention and then further generalized to multiheaded attention. We further combined multiheaded attention with deep learning to create the transformer architecture.\n",
    "3. Trained our transformer and generate code output.\n",
    "\n",
    "Up to this point, the performance of our simple language model has clearly made a lot of progress. We can see that our model has learned to generate in the style of python code syntax, although there are many quirks that suggest it will not make a very practical code assistant in its current state.\n",
    "\n",
    "### Project Outline\n",
    "\n",
    "Find some area of possible improvement.\n",
    "We interpret \"improvement\" quite loosely, but it is up to you to state precisely in what sense your proposed innovation might constitute an improvement and to show convincing evidence that your innovation does or does not constitue an improvement according to your definition.\n",
    "For your idea, **formulate a hypothesis** for why this change should result in a better model. **Implement your changes** and **report any findings**.\n",
    "\n",
    "_Notes_: As this assignment is being treated as a project, you should expect training to take longer than previous assignments. However, please use your judgement to decide what is reasonable. We will not expect you to run training procedures that take more than 2 hours on the free Google Colab computing resources and we certainly do not expect you to acquire additional compute. The proposed improvements should not solely rely on increased computing demands, but must be based on the goal of improving the model by more efficiently learning from our data.\n",
    "\n",
    "_Hints_: There are many aspects to assessing our model. For example, not only is quality of generated text important, it is also of interest to reduce costs associated with training.\n",
    "\n",
    "### Deliverables\n",
    "\n",
    "In addition to a pdf of your python notebook, the submission for this project will be a written report no more than 4 pages in length using the [NeurIPS LaTex template](https://neurips.cc/Conferences/2023/PaperInformation/StyleFiles). Your report should include detailed analysis of the hypotheses you chose to test along with any conclusions.\n",
    "\n",
    "The page limit for the report does not include bibliography or appendices. Make sure to keep the \"ready for submission\" option to help us grade anonymously. One of your apprendices should contain a link to any code used to generate the project so that we can grade it (google drive with colab nbs or github repo are both fine). You should have at least one plot in your main text (which is capped at 4 pages).\n",
    "\n",
    "### Data augmentation\n",
    "\n",
    "We got the data for this project from [The Stack](https://huggingface.co/datasets/bigcode/the-stack-dedup). If you'd like, you can definitely train on larger datasets by accessing their dataset of python code (we just scratched the surface). You have to make an account on Hugginface to get a Hugginface access token, but the process is pretty quick."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# S4 Mamba (Called S6 because idk)"
   ],
   "metadata": {
    "id": "hsxkESKIkocQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## General Idea"
   ],
   "metadata": {
    "id": "Goq_JEu0kq0y"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We want to implement [Mamba](https://arxiv.org/abs/2312.00752). This is a new way of thinking about long range sequence modeling and as such we will be expanding our view beyond simply saying \"let's connect everything and see what happens.\" I view Mamba as a reasonable comparison to Transformers because they are both adapted to the GPU and take full advantage of them. We will first implement S4 Mamba and then attempt to do some purturbations of the idea.\n",
    "\n",
    "I will attempt to follow, as closely as possible, the notation of the original paper while still following Python Conventions.\n",
    "\n",
    "Generally Mamba is taking the original S4 layers and enabling Time variance. S5 could do this well but all of the code is in JAX which seems hard to write in (at least for me right now). I want to get a working Mamba model and then see if I can build on it"
   ],
   "metadata": {
    "id": "pYSxq5zuksv8"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I also want to move this to JAX at some point, but first I will just implement it in PyTorch because I know that better (I tried to do JAX but it was hard at first)"
   ],
   "metadata": {
    "id": "zTWAu04O8BeD"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we want to develop based on the algorithm given here:\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# all imports at the top so nothing here"
   ],
   "metadata": {
    "id": "qjr5UkpZMLUT"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": [],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
